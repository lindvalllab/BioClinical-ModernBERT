{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de13a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e308379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"/home/ubuntu/Bio_Clinical_MBERT/outputs/MedQA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "399c25f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filename(filename):\n",
    "    \"\"\"\n",
    "    Extract hyperparameters from the filename.\n",
    "    Expected format: lr=<lr>_wd=<wd>_epochs=<epochs>_seed=<seed>_effective_batch_size=<effective_bs>.txt\n",
    "    \"\"\"\n",
    "    pattern = r\"lr=([^_]+)_wd=([^_]+)_epochs=([^_]+)_seed=([^_]+)_effective_batch_size=([^\\.]+)\"\n",
    "    match = re.search(pattern, filename)\n",
    "    if match:\n",
    "        lr, wd, epochs, seed, effective_bs = match.groups()\n",
    "        return {\n",
    "            \"lr\": float(lr),\n",
    "            \"wd\": float(wd),\n",
    "            \"epochs\": int(epochs),\n",
    "            \"seed\": int(seed),\n",
    "            \"effective_batch_size\": int(effective_bs)\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def parse_log_file(filepath):\n",
    "    \"\"\"\n",
    "    Parse the log file content, which is assumed to contain lines of the form 'Key: Value'.\n",
    "    \n",
    "    This function ignores lines with keys in the ignore list so that the DataFrame doesn't pick up\n",
    "    headers or unwanted entries.\n",
    "    \"\"\"\n",
    "    ignore_keys = {\"test evaluation results\", \"epoch\", \"seed\", \"effective batch size\", \"eval_samples_per_second\", \"eval_steps_per_second\", \"eval_loss\"}\n",
    "    data = {}\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        # Skip lines that are empty or do not contain a colon.\n",
    "        if not line or \":\" not in line:\n",
    "            continue\n",
    "        key, value = line.split(\":\", 1)\n",
    "        key = key.strip()\n",
    "        # If the lowercase key is in the ignore list, skip it.\n",
    "        if key.lower() in ignore_keys:\n",
    "            continue\n",
    "        value = value.strip()\n",
    "        # If the value is an empty string, set it to np.nan.\n",
    "        if value == \"\":\n",
    "            data[key] = np.nan\n",
    "        else:\n",
    "            # Try to convert to a float if possible.\n",
    "            try:\n",
    "                # If value contains a decimal point then convert to float, otherwise try int.\n",
    "                if \".\" in value:\n",
    "                    data[key] = float(value)\n",
    "                else:\n",
    "                    data[key] = int(value)\n",
    "            except ValueError:\n",
    "                data[key] = value  # keep as string if conversion fails\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9590708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No log files found in /home/ubuntu/Bio_Clinical_MBERT/scripts/outputs/MedQA\n",
      "Individual results:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [] \n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Define aggregation: for each metric, compute mean, median, min, and max.\u001b[39;00m\n\u001b[32m     43\u001b[39m agg_funcs = {col: [\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmedian\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m metric_cols}\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m grouped = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup_cols\u001b[49m\u001b[43m)\u001b[49m.agg(agg_funcs)\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Flatten the multi-level column index.\u001b[39;00m\n\u001b[32m     47\u001b[39m grouped.columns = [\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m.join(col).strip() \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m grouped.columns.values]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/bert24/lib/python3.11/site-packages/pandas/core/frame.py:9183\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9181\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9186\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9189\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9193\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/bert24/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1329\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1329\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/bert24/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:1043\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1041\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m   1046\u001b[39m     exclusions.add(gpr.key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Model'"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "\n",
    "# Recursively find all .txt files in the directory.\n",
    "filepaths = glob.glob(os.path.join(results_path, \"**\", \"*.txt\"), recursive=True)\n",
    "if not filepaths:\n",
    "    print(f\"No log files found in {results_path}\")\n",
    "\n",
    "for filepath in filepaths:\n",
    "    filename = os.path.basename(filepath)\n",
    "    # Assume that the model name is the immediate parent folder.\n",
    "    model = os.path.basename(os.path.dirname(filepath))\n",
    "    \n",
    "    params = parse_filename(filename)\n",
    "    if params is None:\n",
    "        print(f\"Filename {filename} does not match the expected pattern. Skipping file.\")\n",
    "        continue\n",
    "    \n",
    "    log_data = parse_log_file(filepath)\n",
    "    \n",
    "    # Combine the data from the filename, file content, and model name.\n",
    "    record = {\n",
    "        \"Model\": model,\n",
    "        **params,  # Contains keys: lr, wd, epochs, seed, effective_batch_size\n",
    "    }\n",
    "    record.update(log_data)\n",
    "    records.append(record)\n",
    "\n",
    "# Create a DataFrame from the records.\n",
    "df = pd.DataFrame(records)\n",
    "print(\"Individual results:\")\n",
    "print(df.head(), \"\\n\")\n",
    "\n",
    "# Group on Model, lr, wd, and effective_batch_size.\n",
    "group_cols = [\"Model\", \"lr\", \"wd\", \"effective_batch_size\", \"epochs\"]\n",
    "ignore_cols = set(group_cols + [\"seed\"])\n",
    "metric_cols = [col for col in df.columns if col not in ignore_cols]\n",
    "\n",
    "# Convert each metric column to numeric (coercing errors to NaN).\n",
    "for col in metric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# Define aggregation: for each metric, compute mean, median, min, and max.\n",
    "agg_funcs = {col: [\"mean\", \"median\", \"min\", \"max\"] for col in metric_cols}\n",
    "grouped = df.groupby(group_cols).agg(agg_funcs)\n",
    "\n",
    "# Flatten the multi-level column index.\n",
    "grouped.columns = [\"_\".join(col).strip() for col in grouped.columns.values]\n",
    "grouped = grouped.reset_index()\n",
    "\n",
    "for col in grouped.columns:\n",
    "    if \"f1\" in col.lower():\n",
    "        grouped[col] = (grouped[col] * 100).round(1)\n",
    "\n",
    "\n",
    "print(\"Aggregated results over seeds:\")\n",
    "print(grouped.head())\n",
    "\n",
    "# Optionally, save the aggregated DataFrame to CSV.\n",
    "output_csv = os.path.join(results_path, \"aggregated_results.csv\")\n",
    "grouped.to_csv(output_csv, index=False)\n",
    "print(f\"\\nAggregated results saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc10033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.sort_values(by='accuracy_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d7383c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
